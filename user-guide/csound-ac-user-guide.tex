\documentclass[letterpaper,10pt,DIV=12,parskip=half]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage{microtype} % Improved justification and kerning
\usepackage{lmodern}   % Improved font rendering
\usepackage{graphicx}
\usepackage{color}
\usepackage{fancyvrb}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{pstricks}
\usepackage[framemethod=xcolor]{mdframed}

% Define a global background color
\definecolor{framebg}{rgb}{0.9,0.9,0.9} % Light gray background


% Configure hyperref for blue URL links
\hypersetup{
    colorlinks=true,     % Enables colored links
    linkcolor=black,     % Keeps section and figure references black
    citecolor=black,     % Keeps citations black
    urlcolor=blue        % Colors URLs blue
}

\definecolor{palegray}{RGB}{245, 245, 245}  % Light gray
\definecolor{palecanary}{RGB}{255, 255, 215} % Pale canary yellow

% Set global mdframed options
\mdfsetup{
    skipabove=10pt,
    skipbelow=10pt,
    innertopmargin=5pt,
    innerbottommargin=5pt,
    innerleftmargin=10pt,
    innerrightmargin=10pt,
    linewidth=1pt,
    roundcorner=5pt
}

% Define a framed style with a pale gray background
\newmdenv[
    backgroundcolor=palegray,
    linecolor=black
]{grayframed}

% Define a framed style with a pale canary background
\newmdenv[
    backgroundcolor=palecanary,
    linecolor=black
]{canaryframed}

\pagecolor{white}

\begin{document}
\definecolor{LstColor}{cmyk}{0.1,0.1,0,0.05} 
\lstset{language=c++,basicstyle=\ttfamily\normalsize,commentstyle=\ttfamily\normalsize,tabsize=2,breaklines,backgroundcolor=\color{LstColor},fontadjust=true,fancyvrb=true,moredelim=[is][\textbf]{\\emph\{}{\}}}.

\title{CsoundAC User Guide (Mostly for Python)}
\author{Michael Gogins \\ \texttt{michael.gogins@gmail.com}}
\maketitle

\section{Introduction}

CsoundAC is a class library and software toolkit designed to support the algorithmic composition of music. CsoundAC has C++, Python, and JavaScript application programming interfaces (APIs). This \emph{\textbf{Guide}} is based on the Python interface. 

References herein are all in the form of colored hyperlinks to resources on the World Wide Web. Reference documentation for CsoundAC is \href{https://github.com/gogins/csound-ac/blob/master/csound-ac.pdf}{here}.

The major features of CsoundAC are:

\begin{itemize}
\item  \href{https://quod.lib.umich.edu/i/icmc/bbp2372.1998.298/1}{Music graphs}, a hierarchical representation of musical scores and processes, modeled upon the computer graphics idea of scene graphs. 

\item A variety of nodes for use in music graphs, including random variables, dynamical systems, Lindenmayer systems, iterated function systems, and others.

\item Operations on scores using aspects of mathematical music theory, including chord spaces, chord transformations, voice-leading, and automatic modulations. 

\item As the name suggests, CsoundAC interfaces closely with \href{https://csound.com/}{Csound}. However, CsoundAC can also be used with any other computer music system that supports Python scripting, including digital audio workstations (DAWs) such as \href{https://www.reaper.fm/}{Reaper}.

\end{itemize}

\noindent The core of CsoundAC is written in platform-neutral standard C++. The \href{https://github.com/gogins/csound-ac}{CsoundAC repository} also includes a Python interface to CsoundAC. A JavaScript interface to a WebAssembly (WASM) build of CsoundAC (and of Csound) is available in the \href{https://github.com/gogins/csound-wasm}{csound-wasm} repository. 

\section{Getting Started}

\subsection{Installation}

\subsubsection{Installing Prebuilt Binaries}

Prebuilt binaries of CsoundAC for macOS and Linux are available as GitHub releases. These are built for a specific version of Python, and will work only with that version. If you don't have the correct version of Python, you should install that version alongside your existing Python. There are also dependencies on a number of other \href{https://github.com/gogins/csound-ac/blob/master/dependencies/update-dependency-packages.sh}{packages}.

\subsubsection{Building from Source Code}

Binaries for CsoundAC on Linux can also be built from source code by the user as follows:

\begin{enumerate}
\item Clone the \href{https://github.com/gogins/csound-ac}{csound-ac} repository, and open a terminal in the repository's root directory.
\item Install dependencies by running the \lstinline{update-dependencies.sh} script.
\item Perform a fresh build by running the \lstinline{clean-build-linux.sh} script.
\end{enumerate}

\subsection{Configuration}

The following instructions are for binary releases that you have downloaded from GitHub and unzipped in your home directory.

\subsubsection{On macOS}

You need to have installed the Terminal app and, preferably, \href{https://brew.sh/}{Homebrew}.

Unzip the CsoundAC file, open a terminal, and change to the root directory of the unzipped files. Then copy the shared libraries to your Homebrew \lstinline|lib| directory and the \lstinline|site-packages| files to your Homebrew \lstinline|site-packages|. For example, if the Python version for CsoundAC is 3.12:

\begin{lstlisting}
cd ~Downloads
unzip csound-ac-0.6.0-Darwin.zip -d csound-ac
cd csound-ac
cp lib/lib* /opt/homebrew/lib/
cp lib/python/site-packages/* /opt/homebrew/lib/python3.12/site-packages/
\end{lstlisting}

These files must be installed in system directories so that Reaper can load them.

Run the correct version of Python and import the CsoundAC and GeneralizedContextualGroup modules. 

\begin{lstlisting}[basicstyle=\small\ttfamily]
michaelgogins@macbookpro ~/csound-ac % python3.12
Python 3.12.8 (main, Dec  3 2024, 18:42:41) [Clang 16.0.0 (clang-1600.0.26.4)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>> import CsoundAC
>>> import GeneralizedContextualGroup
>>> 
\end{lstlisting}

The macOS Gatekeeper will probably refuse to open the shared libraries, and encourage you to delete them. Instruct the system to open these files anyway:

\begin{enumerate}
\item Open \emph{System Settings} â†’ \emph{Privacy \& Security}.
\item Scroll down to \emph{Security}.
\item Look for a message about the blocked library and click \emph{Allow Anyway}.
\end{enumerate}

You will have to do this both for \lstinline|_CsoundAC.so| and \lstinline|libCsoundAC.dylib|. When both have been allowed, the import should succeed.

\subsubsection{On Linux}

On Linux, unzip the CsoundAC archive in your home directory add the following lines to your \lstinline|.profile| script:

\begin{lstlisting}
export LD_LIBRARY_PATH=~/csound-ac-0.6.0-linux/lib:$LD_LIBRARY_PATH
export PYTHONPATH=~/csound-ac-0.6.0-linux/site-packages:$PYTHONPATH
\end{lstlisting}

Then in your home directory, execute \lstinline|source .profile|.

Run the correct version of Python and import the CsoundAC and GeneralizedContextualGroup modules. 

\begin{lstlisting}[basicstyle=\small\ttfamily]
michaelgogins@macbookpro ~/csound-ac % python3.12
Python 3.12.8 (main, Dec  3 2024, 18:42:41) [Clang 16.0.0 (clang-1600.0.26.4)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>> import CsoundAC
>>> import GeneralizedContextualGroup
>>> 
\end{lstlisting}

There should be no errors.

\subsubsection{Configuring ctcsound}

Each published release of Csound comes with a Python interface to the complete Csound API, defined in the \lstinline|ctcsound.py| module. This module will work with any version of Python, but is built for a specific version of Csound. To enable ctcsound:

\begin{enumerate}

\item Go the Csound GitHub repository, select the \lstinline|csound6| branch, and copy or download the \lstinline|interfaces/ctcsound.py| file to the \lstinline|site-packages| directory for the version of Python that you will use, e.g. \lstinline|/opt/homebrew/lib/python3.12/site-packages/ctcsound.py|.

\item Test your installation by running the correct version of Python and importing the ctcsound module. There should be no error.

\begin{lstlisting}[basicstyle=\small\ttfamily]
michaelgogins@macbookpro ~/csound-ac/user-guide % python3.12
Python 3.12.8 (main, Dec  3 2024, 18:42:41) [Clang 16.0.0 (clang-1600.0.26.4)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>> from ctcsound import *
>>> 
\end{lstlisting}

\end{enumerate}

\subsubsection{Configuring Reaper}

Additional configuration is required to enable Python and CsoundAC in Reaper. To enable Python scripting:

\begin{enumerate}
\item In Reaper, open the \emph{REAPER} menu \emph{Settings...} dialog (might be \emph{Configuration...} on other versions of Reaper).
\item Go to the end of the list of settings, and select \emph{ReaScript}.
\item In the ReaScript settings, check the \emph{Enable Python for use with ReaScript} box.
\item On macOS:
\begin{enumerate}
\item In the \emph{Force ReaScript to use specific Python .dylib} text field, enter the filename of the Python shared library for the version required by CsoundAC, e.g. \lstinline|libpython3.12.dylib|. 
\item In the \emph{Custom path to Python dll directory} field, enter the full path to the Python library root directory, e.g. \lstinline|/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib|. You can use the \emph{Browse} button to select this directory.
\item If the configuration is correct, you will see something like \emph{Python: libpython3.12.dylib installed}.
\end{enumerate}
\item On Linux:
\begin{enumerate}
\item In the \emph{Force ReaScript to use specific Python .so} text field, enter the filename of the Python shared library for the version required by CsoundAC, e.g. \lstinline|libpython3.12.so|. 
\item In the \emph{Custom path to Python dll directory} field, enter the full path to the Python library root directory, e.g. \lstinline|/usr/lib/libpython3.12.so| or \lstinline|/usr/lib/x86_64-linux-gnu/libpython2.12.so|. You can use the \emph{Browse} button to select this directory.
\item If the configuration is correct, you will see something like \emph{Python: libpython3.12.so installed}.
\end{enumerate}
\end{enumerate}

\noindent To enable CsoundAC:

\begin{enumerate}
\item Exit Reaper, and run it again.
\item Use the \emph{Actions} menu, \emph{New action...} dialog, ``Load ReaScript..." dialog to load the \lstinline|ac_reaper.py| script.
\item Create a track with a blank MIDI item, and select that item.
\item Use the \emph{Actions} menu, \emph{Show action list...} dialog, select the \emph{ac\_reaper.py} script, and click on the \emph{Run} button. 
\item You should see the \emph{ReaScript console output} dialog, with output from the \emph{ac\_reaper.py} script. It should look something like this:

\begin{lstlisting}[basicstyle=\small\ttfamily]
Hello, Reaper!
Selected item: <class 'str'> (MediaItem*)0x000000014383A400
Using active take of selected MIDI item.
Start time of the selected MIDI item: 0.00 seconds.
Event count: note_count: 4 cc_count: 0 text_sysex_count: 0
Cleared all contents from the MIDI item.
Inserting note: Start: 0 Start PPQ: 0.0 End PPQ; 960.0 Key: 60 Velocity: 100
Inserting note: Start: 0.5 Start PPQ: 960.0 End PPQ; 1920.0 Key: 62 Velocity: 100
Inserting note: Start: 1 Start PPQ: 1920.0 End PPQ; 2880.0 Key: 64 Velocity: 100
Inserting note: Start: 1.5 Start PPQ: 2880.0 End PPQ; 5760.0 Key: 67 Velocity: 100
MIDI notes added successfully! Check the editor.
\end{lstlisting}
\item If you see the generated notes in the MIDI editor, and there is no error message, then your configuration is correct.
\item If you see the generated notes but also see \emph{WARNING: Could not import CsoundAC!}, then Reaper can run Python code, but the installation or configuration for CsoundAC is not correct. The most likely causes are that the custom path to the Python library is not correct, or CsoundAC files are not located in the correct \lstinline|site-packages| directory.
\end{enumerate}

\section{Examples}

The following examples proceed step by step, repeating each example in standalone Python, Csound's score bin facility, and Python in Reaper:

\begin{enumerate}
\item Generate a chromatic scale using just Csound and Python.
\item Generate the same chromatic scale using CsoundAC.
\item CsoundAC compositions demonstrating some capabilities of CsoundAC.
\end{enumerate}

For insight into the code, go to the hyperlinked source code or open the examples in an editor, and read them in order; there are many explanatory comments.

\begin{canaryframed}
And in the following, specifically \emph{compositional} remarks are framed like this.
\end{canaryframed}

\subsection{Basic Python Usage}

Here, the same very basic example is run in three environments. All three examples use the same Csound orchestra, \href{https://github.com/gogins/csound-ac/blob/master/user-guide/basic.csd}{\lstinline|basic.csd|}, which is defined in the Python code as a Python string literal (\lstinline|(r"some string with perhaps many lines and escape characters"|). All three examples use a simple \lstinline|for| loop to generate an ascending chromatic scale of notes over five octaves. The only differences between the examples are in how they are run, and how they interface with Csound. CsoundAC is not used --- these examples show only the most basic, low-level method of generating a score with Python.

\begin{canaryframed}
The ascending scale is used as a deliberately simple starting point. However, note that the alternation of Csound instruments in overlapping notes, some of which contain internally varying sounds, creates a more complex texture than might be expected.
\end{canaryframed}

\subsubsection{Running in Python: \href{https://github.com/gogins/csound-ac/blob/master/user-guide/basic-python.py}{\lstinline|basic-python.py|}}

Running in Python has the advantage of being easy to understand. A composition is just a Python program. This example uses the ctcsound module to perform the example.

Open a terminal, change to the \lstinline|csound-ac/user-guide| directory, and execute \lstinline|python3.12 basic-python.py|.

\subsubsection{Running in Csound: \href{https://github.com/gogins/csound-ac/blob/master/user-guide/basic-score-bin.csd}{\lstinline|basic-score-bin.csd|}}

Running in Csound has the advantage of requiring no additional installation or configuration apart from Csound, Python, and CsoundAC. All of the elements of a composition are defined in one .csd file. In this case the Csound orchestra is defined outside of the Python code, which is embedded in the .csd file.

Thus, code for running Csound is not needed, as Csound is already running; instead, the script writes the generated score to a temporary filename, and Csound reads that score and performs it. 

Open a terminal, change to the \lstinline|csound-ac/user-guide| directory, and execute \lstinline|csound basic-score-bin.csd|.

\subsubsection{Running in Reaper: \href{https://github.com/gogins/csound-ac/blob/master/user-guide/basic-reascript.py}{\lstinline|basic-reascript.py|}}

Running in Reaper has the advantages of automatically providing a piano roll score, or even music notation, for generated scores; enabling other synthesis plugins besides Csound to render CsoundAC scores; and in general, integrating with contemporary music production practice. The Csound orchestra is defined in the state of a \href{https://github.com/gogins/csound-vst3}{CsoundVST3} plugin, which receives MIDI input from the DAW. The compositional code is defined in a Python ReaScript file, which is loaded into Reaper as an Action. 

This separation of concerns between composition and synthesis enables CsoundAC to send MIDI to the DAW and to other plugins, and for Csound to receive MIDI and audio from any track or plugin in Reaper.

Use the \emph{Actions} menu, \emph{New action...} dialog, ``Load ReaScript..." dialog to load the \lstinline|basic-reascript.py| script. Create a track with a blank MIDI item, and select that item. Use the\emph{Actions} menu, \emph{Show action list...} dialog, select the \emph{basic-reascript.py} script, and click on the \emph{Run} button. 

You should see the \emph{ReaScript console output} dialog, with output from the script. You should also see the notes of the chromatic ascending scale in the MidiItem. You can then assign a synthesizer, which could be CsoundVST3 or another synthesizer, to play the notes.

\subsection{Minimal CsoundAC Examples}

These three examples re-create the three basic examples above, changing them only to generate the ascending chromatic scale as a CsoundAC ScoreNode object, and to render that using CsoundAC's integration with Csound.

\begin{enumerate}

\item Running in Python: \href{https://github.com/gogins/csound-ac/blob/master/user-guide/csoundac-basic-python.py}{\lstinline|csoundac-basic-python.py|}.

\item Running in Csound: \href{https://github.com/gogins/csound-ac/blob/master/user-guide/csoundac-basic-score-bin.csd}{\lstinline|csoundac-basic-score-bin.csd|}.

\item Running in Reaper: \href{https://github.com/gogins/csound-ac/blob/master/user-guide/csoundac-basic-reascript.py}{\lstinline|csoundac-basic-reascript.py|}.

\end{enumerate}

\subsection{Compositional Examples}

\begin{canaryframed}
My paper \href{https://arxiv.org/pdf/2305.15601}{\emph{Metamathematics of Algorithmic Composition}} presents an analysis of the advantages and limitations of algorithmic composition in general. The paper is written at the level of undergraduate theoretical computer science. This reference can be skipped, but provides a deeper context for some of the remarks on algorithmic composition that follow below.

To sum it up, algorithmic composition is capable of approximating, as closely as one likes, any possible piece of music. Furthermore, different algorithms can be placed in musically intelligible relationships to one another, such that it is possible,\emph{ in principle}, to plot a map where each point on the map represents a composition, and compositions that are closely related to each other musically are located near each other on this map. It would then be possible to compose by interactively exploring this map. Nevertheless, the number of possible algorithms is so vast that it is simply not possible, \emph{in practice,} to construct a usable map of related algorithms. That would take an impossibly long time --- but much faster computers might make it possible.
\end{canaryframed}

\subsubsection{How CsoundAC Works}

CsoundAC is based upon the concept of a \emph{\href{https://quod.lib.umich.edu/i/icmc/bbp2372.1998.298/1}{music graph},} which is a tree (directed acyclical graph) of Nodes in score space. This concept is quite similar to the concept of a \emph{\href{https://dl.acm.org/doi/pdf/10.1145/360349.360354}{scene graph}} in 3-dimensional computer graphics, in which objects in a scene are similarly organized as a tree of nodes in 3-dimensonal space. Score space, however, has 12 dimensions:

\begin{description}
\item[TIME] Time in seconds relative to the origin of the space.
\item[DURATION] The duration of this event in seconds.
\item[STATUS] MIDI status number, normally 144 for "note on."
\item[INSTRUMENT] MIDI channel number or Csound instrument number - 1.
\item[KEY] MIDI key number from 0 to 127 in semitones; may have a fractional part to represent microtones; middle C is 60.
\item[VELOCITY] MIDI velocity number from 0 to 127; can loosely be considered decibels of sound pressure level.
\item[PHASE] Phase of the sound, used mostly for Events that represent grains of sound.
\item[PAN] Location in physical space from left to right, in the interval [0, 1] where .5 is the center.
\item[DEPTH] Location in physical space from in front to behind, in the interval [0, 1] where .5 is the center.
\item[HEIGHT] Location in physical space from below to above, in the interval [0, 1] where .5 is the center.
\item[PITCHES] Represents a pitch-class set as a sum of powers of 2 where each power represents one of the pitch-classes in 12 tone equal temperament.
\item[HOMOGENEITY] Set to 1 to enable transformation of Events using homogeneous matrix transformations.
\end{description}

A point in score space most often represents a musical note, but can also represent a chord or scale, a change in a control parameter, or even a grain of sound. The semantics of these dimensions is based on MIDI channel messages, but they have floating-point precision and add duration and other fields.

The following algorithm is used by CsoundAC to generate scores. A composition is an instance of the MusicModel class, which contains a tree of child Nodes representing the music graph, a Csound orchestra, and an embedded instance of Csound. The algorithm performs a depth-first traversal of the music graph by recursively calling each child's \lstinline|void Node::traverse(const Eigen::MatrixXd &global_coordinates, Score &global_score)| method:

\begin{itemize}
\item Multiply the global coordinates by the local coordinates to obtain composite coordinates.
\item Descend into each of this Node's child Nodes with the composite coordinates and an empty Score.
\item Call \lstinline|Node::transform| to transform any or all Events produced by the child nodes, which are in the composite coordinate system.
\item Add the child Events to the global score.
\item Create another empty Score in which to optionally generate new Events, and call \lstinline|Score::transform| to move these new Events into the composite coordinate system.
\item Add these generated Events to the global score.
\end{itemize}

In standalone Python, once the global Score has been generated, the MusicModel uses an embedded instance of Csound to compile its orchestra, translates the global CsoundAC Score to a Csound score, and renders that score with the orchestra.

In Csound using the \lstinline|<CsScore bin=python3>| facility, the generated Score must be translated to a Csound score and written to the temporary filename.

In Python ReaScript, Csound is not used directly; the generated Score must be passed to the \lstinline|ac_reaper.score_to_midiitem| function; any synthesizer plugin (including CsoundVST3) can then be used to render the Score.

The following three examples demonstrate some typical uses of CsoundAC. Two implementations are provided for each example: as standalone Python, and as Python ReaScript for Reaper. Please note, if Reaper hangs when running a Python script, that may be caused by code that calls Python's \lstinline|print| function rather than \lstinline|RPR_ShowConsoleMsg|. In that case, run Reaper from the Terminal command line by executing: \lstinline|/Applications/REAPER.app/Contents/MacOS/REAPER|.

\subsubsection{Transforming Source Material: \href{https://github.com/gogins/csound-ac/blob/master/user-guide/python-trans-scale.py}{\lstinline|python-trans-scale.py|}}

This piece takes the ascending chromatic scale of the previous examples, and uses CsoundAC to transform and elaborate it. 

\begin{enumerate}
\item Play the scale.
\item Repeat that scale, shuffled so that notes are in random order.
\item Repeat that transformed scale, but change the note durations so that the random notes form a connected line.
\item Repeat that connected scale, but make the movements of the voice from note to note occur within a more restricted range.
\item Repeat that transformed scale three times, as a canon at the sixth, on offset beats.
\item Repeat that canon, and apply to it semi-randomized tonal chord progressions and modulations.
\end{enumerate}

Read the code for more details.

\begin{canaryframed}
CsoundAC provides two facilities for working with harmony. The first is based on neo-Riemannian chord transformations, e.g. the \href{https://www.mtosmt.org/issues/mto.05.11.3/mto.05.11.3.fiore_satyendra.pdf}{Generalized Contextual Groups} of Fiore and Satyendra, implemented in the \href{https://dmitri.mycpanel.princeton.edu/files/publications/science2.pdf}{chord spaces} studied by Callendar, Quinn, and Tymoczko. The second is based on \href{https://doi.org/10.1093/oso/9780197577103.001.0001}{tonal harmony as schematized by Tymoczko}, also implemented by me in chord space. The final section of \lstinline|python-trans-scale.py| piece uses my implementation of Tymoczko's scheme.
\end{canaryframed}

\subsubsection{Translating Images to Scores:  \href{https://github.com/gogins/csound-ac/blob/master/user-guide/python-imagery.py}{\lstinline|python-imagery.py|}}

This piece takes a high-resolution digital photograph, and uses CsoundAC to:

\begin{enumerate}
\item Load the photograph in an ImageToScore node.
\item Set a threshold to filter out much of the image, and use only the brighter features.
\item Set a maximum number of simultaneous voices.
\item Call \lstinline|ImageToScore.generateLocally| to translate the brighter features to CsoundAC Events (notes). Hue (color) is instrument, and Value (brightness) is loudness. Saturation is not used.
\item Add the ImageToScore node to a Rescale node.
\item Set appropriate ranges for the various dimensions of the score space in the Rescale node. \emph{Please note: time is not rescaled!} That is so that the duration of the score created by the ImageToScore node can be used to determine the intervals between chords.
\item Use the CsoundAC Scale class to generate a series of chord progressions and modulations.
\item Add the resulting Chords to a VoiceleadingNode, which will apply them to the Events in the generated and rescaled score.
\item Add the Rescale node to the VoiceleadingNode.
\item Add the VoiceleadingNode to the MusicModel.
\item Call \lstinline|MusicModel.generate| to the generate the score, applying each node to the notes produced by its children.
\item Set the final generated score to the desired length.
\item Call \lstinline|MusicModel.perform| to render the score using the Csound orchestra.
\end{enumerate}

\begin{canaryframed}
In a piece like this, the composer must have some sort of starting point such as a specific image, an idea of the density of texture desired, or a Csound orchestra. After that, the piece can only be improved by an iterative process of trial and error. Best practices:
\begin{itemize}
\item Before changing anything, make a backup copy of the current state of the piece. This can be done either by commenting out a line or block of code that has been changed, or by saving versions under different names, or by committing each variant of the piece to a version control system such as Git.
\item Change one thing.
\item Listen to both versions, if necessary all the way through, or even more than time.
\item It may be useful to load two versions into a multitrack audio editor that can show both the spectrum and the wavefrom of each track, and to toggle back and forth between the versions while playing.
\item What may sound worthless at first can sometimes be improved a great deal.
\item If a series of changes ends up spoiling the piece, go back to the last version that you did not make worse, and try changing something other than what you had changed.
\item In the ImageToScore node, there are parameters that can produce different textures from the same image, such as threshold or maximum number of voices.
\item Each pixel in an image might become a separate note, and in a high resolution image, the tempo and density can be high. For example, the image in this example has 4,032 columns of pixels (time steps). In fact, with a fast tempo and a large number of voices, notes will blur into granular type sounds; a score 3 minutes long at this density could have some notes lasting only 0.045 seconds. This may be desirable, or not. If you need a slower tempo, multiply the duration of each note in ImageToScore's score by some factor, and then call \lstinline|ImageToScore.getScore().tieOverlappingNotes()|; or, of course, increase the duration of the piece.
\end{itemize}
\end{canaryframed}

\subsubsection{Lindenmayer Systems in Chord Space: \href{https://github.com/gogins/csound-ac/blob/master/user-guide/python-duo-dualities.py}{\lstinline|python-duo-dualities.py|}}

This piece uses a \href{https://algorithmicbotany.org/papers/abop/abop.pdf}{Lindenmayer system} defined in the \href{https://dmitri.mycpanel.princeton.edu/files/publications/science2.pdf}{voice-leading spaces} of Callendar, Quinn, and Tymoczko to implement the \href{https://www.mtosmt.org/issues/mto.05.11.3/mto.05.11.3.fiore_satyendra.pdf}{Generalized Contextual Groups} of chord transformations identified by Fiore and Satyendra. Here I use the Generalized Contextual Groups to capture the duality of major and minor so constitutive of Western music, in an abstract and generative form that is not specifically ``tonal." This Lindenmayer system, \href{https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=dd8623bbe8c889b2c56d6a1fc0fc55c61b362ee4}{presented by me at the 2009 International Computer Music Conference}, generates a score as movements of chords by transformation through chord space and time, writing notes of the chords to create the score. 

The piece is a modified and elaborated form of \href{https://music.youtube.com/watch?v=3_ahbL44p-E}{\emph{Two Dualities}} by me, presented at the 2010 International Computer Music Conference in the listening rooms as part of \href{http://www.voxnovus.com/60x60/2010_Crimson_Mix.htm}{360 degrees of 60x60 (Crimson Mix)}.

For some hints as to the Lindenmayer system commands in \lstinline|GeneralizedContextualGroup.py|, see the \href{https://github.com/gogins/csound-ac/blob/master/silencio/python/GeneralizedContextualGroup.py}{comments in the source code}.

In the Python version, the same Csound orchestra as the other examples is used to render the piece. In the Reaper version (\href{https://github.com/gogins/csound-ac/blob/master/user-guide/reascript-duo-dualities.py}{reascript-duo-dualities.py} and \href{https://github.com/gogins/csound-ac/blob/master/user-guide/duo-dualities.RPP}{duo-dualities.RPP}), MIDI channels 1 through 3 are routed to one synth (the free and open source \href{https://asb2m10.github.io/dexed/}{Dexed plugin}), and channels 4 through 7 are routed to another synth (the free and open source \href{https://surge-synthesizer.github.io/}{Surge XT plugin}). This demonstrates that the use of CsoundAC is by no means limited to Csound.

\begin{canaryframed}
In the Lindenmayer system for Generalized Contextual Groups, the times that the chords are played are determined solely by the order in which they are written to the score, and their durations. The reason for this is to prevent more than one chord from sounding at the same time. Mathematically speaking, in most music, even atonal music, the harmony is always a function of time. This restriction in the Lindenmayer system means that in it, also, the harmony is always a function of time.

As a result, the structure of a piece cannot be determined by directly specifying the times of the chords. But the structure can be indirectly controlled by using the push and pop commands, which can insert a sequence in the middle of a sequence. Changing the durations and voicings of chords also has an effect on structure.

Please note, the Generalized Contextual Groups have no notion whatsoever of scale, key, cadence, or modulation. Nevertheless, by stringing together chord transformations that can produce a sense of switching between``major" and ``minor," and by often performing the smooth voice-leadings typical of well-formed music, this Lindemayer system can generate a flow of what might be called ``quasi-tonal" music.
\end{canaryframed}

\end{document}
